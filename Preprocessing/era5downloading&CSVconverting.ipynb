{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e91a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ── 1. Imports ────────────────────────────────────────────────────────────────\n",
    "import os, sys, math, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import cdsapi                 # Climate Data Store client\n",
    "import xarray as xr           # convenient NetCDF handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Optional but handy for solar elevation:\n",
    "try:\n",
    "    from astral.sun import elevation as solar_elevation\n",
    "except ImportError:\n",
    "    !pip -q install astral\n",
    "    from astral.sun import elevation as solar_elevation\n",
    "\n",
    "# ── 2. Constants ──────────────────────────────────────────────────────────────\n",
    "LAT, LON = 55.587444, 13.019811 #59.329, 18.068          # Stockholm Central Station  (decimal °)  :contentReference[oaicite:6]{index=6}\n",
    "# 0.125-degree buffer around Stockholm Central\n",
    "BUFFER = 0.01\n",
    "  \n",
    "north = round(LAT + BUFFER, 2)   # → 59.45\n",
    "west  = round(LON - BUFFER, 2)   # → 17.94\n",
    "south = round(LAT - BUFFER, 2)   # → 59.20\n",
    "east  = round(LON + BUFFER, 2)   # → 18.19\n",
    "\n",
    "BOX = [north, west, south, east]\n",
    "\n",
    "# ── Helper to build a dated filename ──────────────────────────────────────────\n",
    "def _make_target(base: str, start, end, ext=\"nc\") -> str:\n",
    "    \"\"\"\n",
    "    Return e.g.  base_20240101_20250101.nc\n",
    "    \"\"\"\n",
    "    start_str = pd.to_datetime(start).strftime(\"%Y%m%d\")\n",
    "    end_str   = pd.to_datetime(end).strftime(\"%Y%m%d\")\n",
    "    return f\"{base}_{start_str}_{end_str}.{ext}\"\n",
    "# ── 3. ERA5 downloader ────────────────────────────────────────────────────────\n",
    "def download_era5_point(start, end, base=\"ERA5_malmö/era5_malmö\"):\n",
    "    target = _make_target(base, start, end)          # <── new line\n",
    "\n",
    "    \"\"\"\n",
    "    Download ERA5 single-level fields for a point (small box) and time span.\n",
    "    start, end : ISO strings 'YYYY-MM-DD' or datetime objects (inclusive)\n",
    "    \"\"\"\n",
    "    start = pd.to_datetime(start)\n",
    "    end   = pd.to_datetime(end)\n",
    "\n",
    "    years  = sorted({d.year  for d in pd.date_range(start, end, freq='D')})\n",
    "    months = sorted({d.month for d in pd.date_range(start, end, freq='D')})\n",
    "    days   = sorted({d.day   for d in pd.date_range(start, end, freq='D')})\n",
    "\n",
    "    hours  = [f\"{h:02d}:00\" for h in range(24)]          # full diurnal cycle\n",
    "\n",
    "    c = cdsapi.Client()                                  # requires ~/.cdsapirc\n",
    "\n",
    "    c.retrieve(\n",
    "        \"reanalysis-era5-single-levels\",                 # dataset id:contentReference[oaicite:7]{index=7}\n",
    "        {\n",
    "          \"product_type\" : \"reanalysis\",\n",
    "          \"variable\"     : [\n",
    "              \"10m_u_component_of_wind\",\n",
    "              \"10m_v_component_of_wind\",\n",
    "              \"total_cloud_cover\"#,\n",
    "              #\"surface_net_solar_radiation\"\n",
    "          ],\n",
    "          \"year\"  : [f\"{y}\"        for y in years ],\n",
    "          \"month\" : [f\"{m:02d}\"    for m in months],\n",
    "          \"day\"   : [f\"{d:02d}\"    for d in days  ],\n",
    "          \"time\"  : hours,\n",
    "          \"area\"  : BOX,           # N W S E in degrees\n",
    "          \"format\": \"netcdf\"\n",
    "        },\n",
    "        target\n",
    "    )\n",
    "    return Path(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811944b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Prerequisite imports ────────────────────────────────────────────────\n",
    "import os, zipfile, tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from astral import Observer\n",
    "from astral.sun import elevation as solar_elevation\n",
    "\n",
    "# Stockholm Central coords\n",
    "LAT, LON = 59.329, 18.068\n",
    "\n",
    "def open_era5_with_stability(path):\n",
    "    \"\"\"\n",
    "    Reads an ERA5 download (zip/netcdf/grib), selects the\n",
    "    nearest point to Stockholm Central, computes wind speed,\n",
    "    wind direction, and Pasquill–Gifford stability (A–F), and\n",
    "    returns an xarray.Dataset.\n",
    "    \"\"\"\n",
    "    # 1. Detect file type (magic number)\n",
    "    with open(path, \"rb\") as f:\n",
    "        sig = f.read(4)\n",
    "    # 2. If ZIP, extract the first .nc inside\n",
    "    if sig.startswith(b\"PK\\x03\\x04\"):\n",
    "        with zipfile.ZipFile(path, \"r\") as z:\n",
    "            nc_files = [fn for fn in z.namelist() if fn.lower().endswith(\".nc\")]\n",
    "            if not nc_files:\n",
    "                raise FileNotFoundError(\"No .nc file inside archive.\")\n",
    "            tmpdir    = tempfile.mkdtemp()\n",
    "            extracted = z.extract(nc_files[0], path=tmpdir)\n",
    "            nc_path   = extracted\n",
    "    else:\n",
    "        nc_path = path\n",
    "\n",
    "    # 3. Choose engine\n",
    "    engine = \"cfgrib\" if sig.startswith(b\"GRIB\") else \"netcdf4\"\n",
    "\n",
    "    # 4. Open dataset\n",
    "    ds = xr.open_dataset(nc_path, engine=engine)\n",
    "\n",
    "    # 5. Rename valid_time→time if present\n",
    "    if \"valid_time\" in ds.coords:\n",
    "        ds = ds.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # 6. Subset to nearest Stockholm Central\n",
    "    ds = ds.sel(latitude=LAT, longitude=LON, method=\"nearest\")\n",
    "\n",
    "    # 7. Wind speed & direction\n",
    "    ds[\"wind_speed\"]     = np.hypot(ds[\"u10\"], ds[\"v10\"])\n",
    "    ds[\"wind_direction\"] = (270 - np.degrees(np.arctan2(ds[\"v10\"], ds[\"u10\"]))) % 360\n",
    "\n",
    "    # 8. Pasquill–Gifford (A–F) via solar elevation + cloud cover\n",
    "    # 8.1 Prepare inputs\n",
    "    times = pd.to_datetime(ds[\"time\"].values)\n",
    "    observer = Observer(latitude=LAT, longitude=LON, elevation=0)\n",
    "    elev      = np.array([solar_elevation(observer, t) for t in times])\n",
    "    ws        = ds[\"wind_speed\"].values\n",
    "    tcc       = ds[\"tcc\"].values.squeeze()  # cloud cover 0–1\n",
    "\n",
    "\n",
    "    # 8.3 Full Pasquill–Gifford lookup driven by the table in the screenshot\n",
    "    def pg(w, elev_deg, cloud):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        w         : wind speed at 10-m height (m s-1)\n",
    "        elev_deg  : solar elevation angle (°) – positive by day, negative at night\n",
    "        cloud     : total cloud cover (fraction 0–1)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str  • stability class A-F\n",
    "        \"\"\"\n",
    "\n",
    "        # --- Helper: bucket insolation by solar elevation ---------------\n",
    "        # Strong  >60°, Moderate 35–60°, Weak <35°\n",
    "        if elev_deg > 60:\n",
    "            ins_cat = \"strong\"\n",
    "        elif elev_deg > 35:\n",
    "            ins_cat = \"moderate\"\n",
    "        elif elev_deg > 0:\n",
    "            ins_cat = \"weak\"\n",
    "        else:\n",
    "            ins_cat = None            # night\n",
    "\n",
    "        # --- DAYTIME branch --------------------------------------------\n",
    "        if ins_cat is not None:\n",
    "            if   w < 2:                       # <2 m/s\n",
    "                return \"A\" if ins_cat in (\"strong\", \"moderate\") else \"B\"\n",
    "            elif w < 3:                       # 2–3\n",
    "                if   ins_cat == \"strong\":     return \"A\"\n",
    "                elif ins_cat == \"moderate\":   return \"B\"\n",
    "                else:                         return \"C\"\n",
    "            elif w < 4:                       # 3–4\n",
    "                if   ins_cat == \"strong\":     return \"B\"\n",
    "                elif ins_cat == \"moderate\":   return \"B\"  # choose the lower value of B-C\n",
    "                else:                         return \"C\"\n",
    "            elif w < 6:                       # 4–6\n",
    "                if   ins_cat == \"strong\":     return \"C\"\n",
    "                elif ins_cat == \"moderate\":   return \"C\"  # lower value of C-D\n",
    "                else:                         return \"D\"\n",
    "            else:                             # >6\n",
    "                if   ins_cat == \"strong\":     return \"C\"\n",
    "                elif ins_cat == \"moderate\":   return \"D\"\n",
    "                else:                         return \"D\"\n",
    "\n",
    "        # --- NIGHT-TIME branch -----------------------------------------\n",
    "        # Cloud categories from table:\n",
    "        #   • 'cloudy'  : thin clouds OR >4/8 low cloud  → cloud ≥ 0.5\n",
    "        #   • 'clear'   : ≤3/8 low cloud                → cloud < 0.5\n",
    "        cloudy = cloud >= 0.5\n",
    "\n",
    "        if cloudy:                    # “Tunna moln eller >4/8 låga”\n",
    "            if   w < 2:  return \"F\"   # table shows F* – treat as F\n",
    "            elif w < 3:  return \"E\"\n",
    "            else:       return \"D\"    # ≥3 m/s all map to D\n",
    "        else:                         # “≤3/8 låga”\n",
    "            if   w < 2:  return \"F\"   # F* in table\n",
    "            elif w < 3:  return \"F\"\n",
    "            elif w < 4:  return \"E\"\n",
    "            else:       return \"D\"\n",
    "\n",
    "\n",
    "    pg_vec = np.vectorize(pg)\n",
    "    classes = pg_vec(ws, elev, tcc)\n",
    "\n",
    "    ds[\"stability_class\"] = xr.DataArray(\n",
    "        classes,\n",
    "        coords={\"time\": ds[\"time\"].values},\n",
    "        dims=[\"time\"]\n",
    "    )\n",
    "\n",
    "    # 9. Cleanup if we unzipped\n",
    "    if sig.startswith(b\"PK\\x03\\x04\"):\n",
    "        try:\n",
    "            os.remove(nc_path)\n",
    "            os.rmdir(tmpdir)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88b2fda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-01-01 00:00:00')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(\"2024-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6e938e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 14:55:30,185 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-07-14 14:55:30,900 INFO Request ID is bc85c745-b591-4ead-b297-b5d85301e086\n",
      "2025-07-14 14:55:31,005 INFO status has been updated to accepted\n",
      "2025-07-14 14:55:45,337 INFO status has been updated to running\n",
      "2025-07-14 15:07:52,709 INFO status has been updated to successful\n",
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → era5_stockholm_20240601_20241231.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Retrieve one year and let the helper name the file\n",
    "nc_file = download_era5_point(\"2024-06-01\", \"2024-12-31\")\n",
    "print(\"Saved →\", nc_file)          # ➞ era5_stockholm_20240101_20250101.nc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52b3b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     wind_speed  wind_direction stability_class  number  \\\n",
      "time                                                                      \n",
      "2024-08-01 00:00:00    3.480160      322.183472               E       0   \n",
      "2024-08-01 01:00:00    3.476162      325.791351               E       0   \n",
      "2024-08-01 02:00:00    3.510871      324.129303               E       0   \n",
      "2024-08-01 03:00:00    3.693168      321.799805               C       0   \n",
      "2024-08-01 04:00:00    3.857137      322.685120               C       0   \n",
      "\n",
      "                     latitude  longitude expver  \n",
      "time                                             \n",
      "2024-08-01 00:00:00     59.32      18.06   0001  \n",
      "2024-08-01 01:00:00     59.32      18.06   0001  \n",
      "2024-08-01 02:00:00     59.32      18.06   0001  \n",
      "2024-08-01 03:00:00     59.32      18.06   0001  \n",
      "2024-08-01 04:00:00     59.32      18.06   0001  \n"
     ]
    }
   ],
   "source": [
    "ds = open_era5_with_stability(\"era5_stockholm_20240801_20241231.nc\")\n",
    "print(ds[['wind_speed','wind_direction','stability_class']].to_dataframe().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79175ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Monthly downloader ──────────────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def download_monthly_series(start_year: int, end_year: int,\n",
    "                            base_dir: str = \"ERA5_malmo\",\n",
    "                            base_name: str = \"era5_malmo\"):\n",
    "    \"\"\"\n",
    "    Loop over every month between start_year and end_year (inclusive),\n",
    "    download that month, and save to <base_dir>/<base_name>_YYYYMMDD_YYYYMMDD.nc\n",
    "    \"\"\"\n",
    "    out_dir = Path(base_dir)\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Build a monthly date index (1st of each month)\n",
    "    dates = pd.date_range(f\"{start_year}-01-01\", f\"{end_year}-12-31\", freq=\"6MS\")\n",
    "\n",
    "    for start in dates:\n",
    "        # last day of the same month\n",
    "        end = (start + pd.offsets.MonthEnd(6)).date()\n",
    "        start_str = start.strftime(\"%Y-%m-%d\")\n",
    "        end_str   = end.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        target = out_dir / _make_target(base_name, start_str, end_str)\n",
    "\n",
    "        if target.exists():\n",
    "            print(f\"✔ {target.name} already exists – skipping\")\n",
    "            continue\n",
    "\n",
    "        print(f\"⇓ Downloading {start_str} → {end_str} …\")\n",
    "        download_era5_point(start_str, end_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277e4f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⇓ Downloading 2024-01-01 → 2024-06-30 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 09:57:16,043 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-07-18 09:57:16,673 INFO Request ID is f79c591d-edf3-4aa7-a791-24ae23080346\n",
      "2025-07-18 09:57:16,767 INFO status has been updated to accepted\n",
      "2025-07-18 09:57:30,894 INFO status has been updated to running\n",
      "2025-07-18 10:07:37,470 INFO status has been updated to successful\n",
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⇓ Downloading 2024-07-01 → 2024-12-31 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 10:07:39,304 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-07-18 10:07:39,917 INFO Request ID is 3196082f-2e1b-4fa6-b02c-d5008642be79\n",
      "2025-07-18 10:07:39,992 INFO status has been updated to accepted\n",
      "2025-07-18 10:07:48,633 INFO status has been updated to running\n",
      "2025-07-18 10:20:02,081 INFO status has been updated to successful\n",
      "                                                                                     \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: grab Jan 2023 → Dec 2024\n",
    "download_monthly_series(2024, 2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba0a3dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⇢ Loading era5_malmo_20240101_20240630.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johan\\miniconda3\\envs\\QRA_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⇢ Loading era5_malmo_20240701_20241231.nc\n",
      "✓ Saved combined CSV → ERA5_malmo\\era5_malmo_2024_combined.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_16680\\3537774544.py:47: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  full_idx = pd.date_range(big_df.index.min(), big_df.index.max(), freq=\"H\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "wind_speed",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "wind_direction",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "stability_class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "expver",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "34186b27-9654-4781-af38-6031e6e00393",
       "rows": [
        [
         "2024-01-01 00:00:00",
         "4.80002",
         "145.52957",
         "D",
         "0",
         "55.58",
         "13.01",
         "0001"
        ],
        [
         "2024-01-01 01:00:00",
         "4.1630025",
         "143.6316",
         "D",
         "0",
         "55.58",
         "13.01",
         "0001"
        ],
        [
         "2024-01-01 02:00:00",
         "4.032418",
         "147.54881",
         "D",
         "0",
         "55.58",
         "13.01",
         "0001"
        ],
        [
         "2024-01-01 03:00:00",
         "3.86002",
         "149.57254",
         "D",
         "0",
         "55.58",
         "13.01",
         "0001"
        ],
        [
         "2024-01-01 04:00:00",
         "3.6247065",
         "149.60184",
         "D",
         "0",
         "55.58",
         "13.01",
         "0001"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>stability_class</th>\n",
       "      <th>number</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>expver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01 00:00:00</th>\n",
       "      <td>4.800020</td>\n",
       "      <td>145.529572</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>55.58</td>\n",
       "      <td>13.01</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 01:00:00</th>\n",
       "      <td>4.163002</td>\n",
       "      <td>143.631607</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>55.58</td>\n",
       "      <td>13.01</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 02:00:00</th>\n",
       "      <td>4.032418</td>\n",
       "      <td>147.548813</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>55.58</td>\n",
       "      <td>13.01</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 03:00:00</th>\n",
       "      <td>3.860020</td>\n",
       "      <td>149.572540</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>55.58</td>\n",
       "      <td>13.01</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 04:00:00</th>\n",
       "      <td>3.624707</td>\n",
       "      <td>149.601837</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>55.58</td>\n",
       "      <td>13.01</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     wind_speed  wind_direction stability_class  number  \\\n",
       "2024-01-01 00:00:00    4.800020      145.529572               D       0   \n",
       "2024-01-01 01:00:00    4.163002      143.631607               D       0   \n",
       "2024-01-01 02:00:00    4.032418      147.548813               D       0   \n",
       "2024-01-01 03:00:00    3.860020      149.572540               D       0   \n",
       "2024-01-01 04:00:00    3.624707      149.601837               D       0   \n",
       "\n",
       "                     latitude  longitude expver  \n",
       "2024-01-01 00:00:00     55.58      13.01   0001  \n",
       "2024-01-01 01:00:00     55.58      13.01   0001  \n",
       "2024-01-01 02:00:00     55.58      13.01   0001  \n",
       "2024-01-01 03:00:00     55.58      13.01   0001  \n",
       "2024-01-01 04:00:00     55.58      13.01   0001  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def combine_monthly_to_csv(\n",
    "    base_dir: str = \"ERA5_files\",\n",
    "    base_name: str = \"era5_stockholm\",\n",
    "    csv_name:  str = \"era5_stockholm_combined.csv\",\n",
    "    hourly_qc: bool = True,          # turn on financial-style gap check\n",
    "    dup_policy: str = \"last\"         # or \"first\" or \"mean\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Load all <base_name>_*.nc files in <base_dir> (monthly ERA5 downloads),\n",
    "    derive wind_speed / wind_direction / stability_class via open_era5_with_stability,\n",
    "    concatenate into one time-indexed DataFrame, optionally enforce a continuous\n",
    "    hourly index (QA), and write to CSV.\n",
    "    \"\"\"\n",
    "    data_dir = Path(base_dir)\n",
    "    files = sorted(data_dir.glob(f\"{base_name}_*.nc\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files matching {base_name}_*.nc in {base_dir}\")\n",
    "\n",
    "    frames = []\n",
    "    for f in files:\n",
    "        print(f\"⇢ Loading {f.name}\")\n",
    "        ds = open_era5_with_stability(str(f))  # use your existing function\n",
    "        df = ds[[\"wind_speed\", \"wind_direction\", \"stability_class\"]].to_dataframe()\n",
    "        frames.append(df)\n",
    "\n",
    "    # Concatenate\n",
    "    big_df = pd.concat(frames)\n",
    "\n",
    "    # Ensure sorted by time\n",
    "    big_df = big_df.sort_index()\n",
    "\n",
    "    # Handle duplicate timestamps (can happen if date ranges overlap)\n",
    "    if dup_policy == \"last\":\n",
    "        big_df = big_df[~big_df.index.duplicated(keep=\"last\")]\n",
    "    elif dup_policy == \"first\":\n",
    "        big_df = big_df[~big_df.index.duplicated(keep=\"first\")]\n",
    "    elif dup_policy == \"mean\":\n",
    "        big_df = big_df.groupby(level=0).mean(numeric_only=True)\n",
    "    else:\n",
    "        raise ValueError(\"dup_policy must be 'last', 'first', or 'mean'.\")\n",
    "\n",
    "    # Optional QA step (financial risk–style: enforce complete grid)\n",
    "    if hourly_qc:\n",
    "        full_idx = pd.date_range(big_df.index.min(), big_df.index.max(), freq=\"H\")\n",
    "        big_df = big_df.reindex(full_idx)  # gaps appear as NaN; no forward fill by default\n",
    "\n",
    "    # Save\n",
    "    out_csv = data_dir / csv_name\n",
    "    big_df.to_csv(out_csv, index_label=\"time\")\n",
    "    print(f\"✓ Saved combined CSV → {out_csv}\")\n",
    "\n",
    "    return big_df\n",
    "\n",
    "# EXAMPLE: combine everything already in ERA5_files/\n",
    "combined_df = combine_monthly_to_csv(\n",
    "    base_dir=\"ERA5_malmo\",\n",
    "    base_name=\"era5_malmo\",\n",
    "    csv_name=\"era5_malmo_2024_combined.csv\",\n",
    "    hourly_qc=True,\n",
    "    dup_policy=\"last\"\n",
    ")\n",
    "\n",
    "combined_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QRA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
